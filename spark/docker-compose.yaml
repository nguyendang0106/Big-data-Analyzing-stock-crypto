  version: '3'

  services:
    # Spark Master
    spark-master:
      image: apache/spark:3.5.0
      container_name: spark-master
      env_file:
        - ../.env
      environment:
        - SPARK_MODE=master
        - SPARK_MASTER_HOST=spark-master
        - SPARK_MASTER_PORT=7077
      networks:
        - spark-network
      ports:
        - "8083:8080"  # Spark UI
        - "7077:7077"  # Spark Master
      command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master"]
    # Spark Worker node 1 (with Driver program)
    spark-worker-driver:
      image: apache/spark:3.5.0
      container_name: spark-worker-driver
      user: root  # <== Gán user có HOME hợp lệ để tránh lỗi Ivy
      environment:
        - GOOGLE_APPLICATION_CREDENTIALS=/opt/spark/google-key.json # <-- Trỏ trực tiếp đến file key đã mount
        - SPARK_MODE=worker
        - SPARK_MASTER=spark://spark-master:7077
        - SPARK_WORKER_CORES=2
        - SPARK_WORKER_MEMORY=2G
        - HOME=/tmp  # <== Đảm bảo thư mục HOME hợp lệ để tránh lỗi spark-submit
      networks:
        - spark-network
      volumes:
        - ./code:/opt/spark/work-dir
        - C:\Users\Admin\Downloads\decoded-tribute-474915-u9-111f1343f6c0.json:/opt/spark/google-key.json
        - ./requirements.txt:/opt/spark/requirements.txt
        - ./start_date.txt:/opt/spark/start_date.txt
        - ./jars/gcs-connector-hadoop3-latest.jar:/opt/spark/jars/gcs-connector-hadoop3-latest.jar
        - ./jars/spark-bigquery-with-dependencies_2.12-0.36.1.jar:/opt/spark/jars/spark-bigquery-with-dependencies_2.12-0.36.1.jar
      command: [
          "/bin/bash", 
          "-c", 
          "sleep 10 && \
          pip install -r /opt/spark/requirements.txt && \
          /opt/spark/bin/spark-submit \
          --master spark://spark-master:7077 \
          --name 'Auto ETL Job' \
          --deploy-mode client \
          --conf spark.driver.extraClassPath='/opt/spark/jars/gcs-connector-hadoop3-latest.jar' \
          --conf spark.executor.extraClassPath='/opt/spark/jars/gcs-connector-hadoop3-latest.jar' \
          --jars /opt/spark/jars/gcs-connector-hadoop3-latest.jar,/opt/spark/jars/spark-bigquery-with-dependencies_2.12-0.36.1.jar \
          /opt/spark/work-dir/write_to_big_query.py; \
          /bin/bash" 
      ]
      depends_on:
        - spark-master
      ports:
        - "4040:4040"

    # Spark Worker 2
    spark-worker-2:
      image: apache/spark:3.5.0
      container_name: spark-worker-2
      user: root
      environment:
        - SPARK_MODE=worker
        - SPARK_MASTER=spark://spark-master:7077
        - SPARK_WORKER_CORES=2
        - SPARK_WORKER_MEMORY=2G
        - HOME=/tmp
      volumes:
        - C:\Users\Admin\Downloads\decoded-tribute-474915-u9-111f1343f6c0.json:/opt/spark/google-key.json
      networks:
        - spark-network
      depends_on:
        - spark-master
      command: [
          "/bin/bash", 
          "-c", 
          "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077"
      ]
      

    # Spark Worker 3
    spark-worker-3:
      image: apache/spark:3.5.0
      container_name: spark-worker-3
      user: root
      environment:
        - SPARK_MODE=worker
        - SPARK_MASTER=spark://spark-master:7077
        - SPARK_WORKER_CORES=2
        - SPARK_WORKER_MEMORY=2G
        - HOME=/tmp
      volumes:
        - C:\Users\Admin\Downloads\decoded-tribute-474915-u9-111f1343f6c0.json:/opt/spark/google-key.json
      networks:
        - spark-network
      depends_on:
        - spark-master
      command: [
          "/bin/bash", 
          "-c", 
          "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077"
      ]

  networks:
    spark-network:
      driver: bridge