# üöÄ H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng Cryptocurrency Crawler

## üì¶ C√†i ƒê·∫∑t

### B∆∞·ªõc 1: C√†i ƒë·∫∑t Python packages

```bash
cd "..."
pip install -r requirements.txt
```

Ho·∫∑c c√†i t·ª´ng package:

```bash
pip install requests pandas numpy schedule openpyxl
```

## üéØ C√°ch S·ª≠ D·ª•ng

### File 1: `test.py` - Basic Crawler

Crawler c∆° b·∫£n v·ªõi CoinGecko API:

```bash
cd data
python test.py
```

**T√≠nh nƒÉng:**

- ‚úÖ Crawl top 50 cryptocurrencies
- ‚úÖ Crawl trending coins
- ‚úÖ Crawl d·ªØ li·ªáu l·ªãch s·ª≠ 30 ng√†y (Bitcoin, Ethereum)
- ‚úÖ Crawl global market data
- ‚úÖ Crawl th√¥ng tin chi ti·∫øt Bitcoin

**Output:** T·∫°o th∆∞ m·ª•c `crypto_data/` v·ªõi c√°c file CSV v√† JSON

### File 2: `crypto_crawler_advanced.py` - Advanced Crawler

Crawler n√¢ng cao v·ªõi nhi·ªÅu ngu·ªìn d·ªØ li·ªáu:

```bash
cd data
python crypto_crawler_advanced.py
```

**Menu ch·ª©c nƒÉng:**

```
1. Crawl Top 100 Cryptocurrencies (CoinGecko)
2. Crawl DeFi Protocols
3. Crawl Binance 24h Ticker
4. Crawl Bitcoin Candlestick + Technical Indicators
5. Crawl Bitcoin Orderbook
6. Crawl t·∫•t c·∫£ (One-time)
7. Ch·∫°y Scheduled Crawler (Auto crawl m·ªói 60 ph√∫t)
```

**T√≠nh nƒÉng n√¢ng cao:**

- ‚úÖ Crawl t·ª´ CoinGecko v√† Binance
- ‚úÖ T√≠nh to√°n technical indicators (SMA, EMA, MACD, RSI, Bollinger Bands)
- ‚úÖ Ph√¢n t√≠ch market sentiment
- ‚úÖ Crawl orderbook depth
- ‚úÖ Scheduled tasks (t·ª± ƒë·ªông crawl ƒë·ªãnh k·ª≥)
- ‚úÖ Logging system

## üìä D·ªØ Li·ªáu Thu Th·∫≠p ƒê∆∞·ª£c

### CoinGecko Data

- **Market Data:** Gi√° hi·ªán t·∫°i, market cap, volume, price changes
- **Historical Data:** Gi√° l·ªãch s·ª≠ theo ng√†y/gi·ªù
- **Trending Coins:** Top trending cryptocurrencies
- **Global Data:** T·ªïng market cap, volume to√†n th·ªã tr∆∞·ªùng
- **Coin Details:** Th√¥ng tin chi ti·∫øt v·ªÅ t·ª´ng coin

### Binance Data

- **24h Ticker:** Th·ªëng k√™ 24h c·ªßa t·∫•t c·∫£ trading pairs
- **Candlestick (Klines):** OHLCV data v·ªõi nhi·ªÅu timeframes
- **Orderbook:** Bid/Ask depth data
- **Technical Indicators:** SMA, EMA, MACD, RSI, Bollinger Bands

## üîß T√πy Ch·ªânh

### Thay ƒë·ªïi s·ªë l∆∞·ª£ng coins crawl:

```python
# Trong test.py ho·∫∑c crypto_crawler_advanced.py
top_coins = crawler.get_top_cryptocurrencies(limit=200)  # Thay ƒë·ªïi t·ª´ 50 -> 200
```

### Thay ƒë·ªïi timeframe d·ªØ li·ªáu l·ªãch s·ª≠:

```python
# Crawl 90 ng√†y thay v√¨ 30 ng√†y
historical = crawler.get_historical_data('bitcoin', days=90)
```

### Thay ƒë·ªïi trading pair tr√™n Binance:

```python
# Crawl Ethereum thay v√¨ Bitcoin
df = crawler.crawl_binance_klines('ETHUSDT', interval='1h', limit=100)
```

### Thay ƒë·ªïi interval cho scheduled crawler:

```python
# Ch·∫°y m·ªói 30 ph√∫t thay v√¨ 60 ph√∫t
crawler.run_scheduler(interval_minutes=30)
```

## üìà Ph√¢n T√≠ch D·ªØ Li·ªáu

### Load v√† ph√¢n t√≠ch d·ªØ li·ªáu ƒë√£ crawl:

```python
import pandas as pd

# Load data
df = pd.read_csv('crypto_data_advanced/coingecko_markets_YYYYMMDD_HHMMSS.csv')

# Top 10 gainers 24h
top_gainers = df.nlargest(10, 'price_change_percentage_24h')
print(top_gainers[['name', 'symbol', 'current_price', 'price_change_percentage_24h']])

# Top 10 losers 24h
top_losers = df.nsmallest(10, 'price_change_percentage_24h')
print(top_losers[['name', 'symbol', 'current_price', 'price_change_percentage_24h']])

# Coins with RSI > 70 (overbought)
btc_data = pd.read_csv('crypto_data_advanced/btc_klines_with_indicators_YYYYMMDD_HHMMSS.csv')
overbought = btc_data[btc_data['RSI'] > 70]
print(f"Overbought periods: {len(overbought)}")
```

## üîÑ Scheduled Crawling

### Ch·∫°y crawler t·ª± ƒë·ªông m·ªói gi·ªù:

```python
from crypto_crawler_advanced import AdvancedCryptoCrawler

crawler = AdvancedCryptoCrawler()
crawler.run_scheduler(interval_minutes=60)  # Crawl m·ªói 60 ph√∫t
```

### Ho·∫∑c s·ª≠ d·ª•ng cron job (Linux/macOS):

```bash
# Ch·ªânh s·ª≠a crontab
crontab -e

# Th√™m d√≤ng n√†y ƒë·ªÉ ch·∫°y m·ªói gi·ªù
0 * * * * cd /path/to/project/data && /usr/bin/python3 crypto_crawler_advanced.py
```

## üìù Logging

Logs ƒë∆∞·ª£c l∆∞u trong file `crypto_crawler.log`:

```bash
# Xem logs real-time
tail -f crypto_crawler.log

# Xem 100 d√≤ng cu·ªëi
tail -n 100 crypto_crawler.log
```

## ‚ö†Ô∏è L∆∞u √ù Quan Tr·ªçng

### Rate Limits

**CoinGecko Free API:**

- ~10-50 requests/ph√∫t
- S·ª≠ d·ª•ng `time.sleep()` gi·ªØa c√°c requests

**Binance API:**

- 1200 requests/ph√∫t cho IP
- 6000 requests/ph√∫t cho UID

### Best Practices

1. **Lu√¥n check response status:**

   ```python
   response.raise_for_status()
   ```

2. **S·ª≠ d·ª•ng timeout:**

   ```python
   requests.get(url, timeout=30)
   ```

3. **Handle exceptions:**

   ```python
   try:
       data = crawler.crawl_data()
   except Exception as e:
       logger.error(f"Error: {e}")
   ```

4. **Rate limiting:**
   ```python
   time.sleep(2)  # Delay 2 gi√¢y gi·ªØa c√°c requests
   ```

## üéì Examples

### Example 1: Crawl v√† analyze Bitcoin

```python
from crypto_crawler_advanced import AdvancedCryptoCrawler

crawler = AdvancedCryptoCrawler()

# Crawl Bitcoin data
df = crawler.crawl_binance_klines('BTCUSDT', interval='1d', limit=365)

# Calculate indicators
df_with_indicators = crawler.calculate_technical_indicators(df)

# Save
crawler.save_data(df_with_indicators, 'btc_yearly_analysis')

# Analyze
print(f"Current RSI: {df_with_indicators['RSI'].iloc[-1]:.2f}")
print(f"MACD: {df_with_indicators['MACD'].iloc[-1]:.2f}")
```

### Example 2: Monitor market sentiment

```python
crawler = AdvancedCryptoCrawler()

# Get market data
df = crawler.crawl_coingecko_markets(limit=100)

# Analyze sentiment
sentiment = crawler.analyze_market_sentiment(df)

print(f"Gainers: {sentiment['gainers']}")
print(f"Losers: {sentiment['losers']}")
print(f"Average 24h change: {sentiment['avg_change_24h']:.2f}%")
```

### Example 3: Compare multiple coins

```python
coins = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'ADAUSDT', 'SOLUSDT']

for coin in coins:
    df = crawler.crawl_binance_klines(coin, interval='1h', limit=24)
    if df is not None:
        price_change = ((df['close'].iloc[-1] - df['close'].iloc[0]) / df['close'].iloc[0]) * 100
        print(f"{coin}: {price_change:+.2f}% (24h)")
    time.sleep(1)
```

## üêõ Troubleshooting

### L·ªói: Module not found

```bash
pip install requests pandas numpy schedule
```

### L·ªói: Rate limit exceeded

```python
# TƒÉng delay gi·ªØa c√°c requests
time.sleep(5)  # Thay v√¨ 2 gi√¢y
```

### L·ªói: Connection timeout

```python
# TƒÉng timeout
response = requests.get(url, timeout=60)  # Thay v√¨ 30
```

## üìö T√†i Li·ªáu API

- [CoinGecko API Docs](https://www.coingecko.com/en/api/documentation)
- [Binance API Docs](https://binance-docs.github.io/apidocs/spot/en/)

## üí° Tips & Tricks

1. **L∆∞u d·ªØ li·ªáu v·ªõi timestamp** ƒë·ªÉ kh√¥ng b·ªã ghi ƒë√®
2. **S·ª≠ d·ª•ng parquet format** cho files l·ªõn (nhanh h∆°n CSV)
3. **Crawl theo batch** ƒë·ªÉ tr√°nh rate limit
4. **Backup d·ªØ li·ªáu ƒë·ªãnh k·ª≥**
5. **Monitor disk space** khi crawl li√™n t·ª•c

## üöÄ Next Steps

- [ ] T√≠ch h·ª£p th√™m exchanges (Coinbase, Kraken, FTX)
- [ ] Th√™m real-time WebSocket streaming
- [ ] X√¢y d·ª±ng database (PostgreSQL/MongoDB)
- [ ] T·∫°o dashboard visualization (Streamlit/Dash)
- [ ] Machine Learning models cho price prediction
- [ ] Alert system cho price movements

---

**Happy Crawling! üéâ**
